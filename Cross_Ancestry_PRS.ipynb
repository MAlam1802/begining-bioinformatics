{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPZJ6MMSGfXCEkI2k0kbfC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAlam1802/begining-bioinformatics/blob/main/Cross_Ancestry_PRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwRhJ-UNdU-A"
      },
      "outputs": [],
      "source": [
        "# Core scientific + plotting stack\n",
        "!pip install -q \\\n",
        "    pandas \\\n",
        "    numpy \\\n",
        "    scipy \\\n",
        "    scikit-learn \\\n",
        "    statsmodels \\\n",
        "    matplotlib \\\n",
        "    seaborn \\\n",
        "    tqdm \\\n",
        "    pyarrow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting defaults\n",
        "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
        "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
        "\n",
        "print(\"Libraries imported and ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHiq5wxVw14R",
        "outputId": "981f184d-188a-4168-b17c-9abded7c243c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported and ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install plink 1.9 binary\n",
        "!wget -qO- http://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20201019.zip > plink.zip\n",
        "!unzip -o plink.zip\n",
        "!chmod +x plink\n",
        "!mv plink /usr/local/bin/\n",
        "\n",
        "!plink --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgmj1_qSxKNh",
        "outputId": "06f3e12f-a87b-4655-cd88-93d4701c8b7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  plink.zip\n",
            "  inflating: plink                   \n",
            "  inflating: LICENSE                 \n",
            "  inflating: toy.ped                 \n",
            "  inflating: toy.map                 \n",
            "  inflating: prettify                \n",
            "PLINK v1.90b6.21 64-bit (19 Oct 2020)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "eur_path = \"GCST90320058EUR.h.tsv.gz\"\n",
        "afr_path = \"GCST90320061AFR.h.tsv.gz\"\n",
        "\n",
        "# Loading with pandas\n",
        "eur_df = pd.read_csv(eur_path, sep=\"\\t\", compression=\"gzip\", low_memory=False)\n",
        "afr_df = pd.read_csv(afr_path, sep=\"\\t\", compression=\"gzip\", low_memory=False)\n",
        "\n",
        "print(\"Loaded EUR GWAS:\", eur_df.shape)\n",
        "print(\"Loaded AFR GWAS:\", afr_df.shape)\n",
        "print(\"EUR columns:\", list(eur_df.columns))\n",
        "print(\"AFR columns:\", list(afr_df.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWU3ZleC3K_l",
        "outputId": "9afcdd08-bc11-450d-84f4-be1093ee616a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded EUR GWAS: (13264860, 17)\n",
            "Loaded AFR GWAS: (19077597, 17)\n",
            "EUR columns: ['chromosome', 'base_pair_location', 'effect_allele', 'other_allele', 'beta', 'standard_error', 'effect_allele_frequency', 'p_value', 'variant_id', 'rsid', 'het_i2', 'het_p_value', 'n_samples', 'n_cases', 'n_studies', 'hm_coordinate_conversion', 'hm_code']\n",
            "AFR columns: ['chromosome', 'base_pair_location', 'effect_allele', 'other_allele', 'beta', 'standard_error', 'effect_allele_frequency', 'p_value', 'variant_id', 'rsid', 'het_i2', 'het_p_value', 'n_samples', 'n_cases', 'n_studies', 'hm_coordinate_conversion', 'hm_code']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def clean_gwas(df, label=\"GWAS\"):\n",
        "    df = df.copy()\n",
        "    print(f\"\\n=== Cleaning {label} ===\")\n",
        "    print(\"Original columns:\", list(df.columns))\n",
        "\n",
        "    # --- 1. Chromosome and position ---\n",
        "    df[\"CHR\"] = pd.to_numeric(df[\"chromosome\"], errors=\"coerce\")\n",
        "    df[\"BP\"]  = pd.to_numeric(df[\"base_pair_location\"], errors=\"coerce\")\n",
        "\n",
        "    # --- 2. SNP ID (rsid preferred) ---\n",
        "    if \"rsid\" in df.columns:\n",
        "        df[\"SNP\"] = df[\"rsid\"]\n",
        "    else:\n",
        "        df[\"SNP\"] = df[\"variant_id\"]\n",
        "\n",
        "    before = df.shape[0]\n",
        "    df = df[~df[\"SNP\"].isna()]\n",
        "    print(f\"{label}: Dropped {before - df.shape[0]} rows with missing SNP IDs.\")\n",
        "\n",
        "    # --- 3. Alleles ---\n",
        "    df[\"A1\"] = df[\"effect_allele\"].astype(str).str.upper()\n",
        "    df[\"A2\"] = df[\"other_allele\"].astype(str).str.upper()\n",
        "\n",
        "    # --- 4. Effect size, SE, p-value ---\n",
        "    df[\"BETA\"] = pd.to_numeric(df[\"beta\"], errors=\"coerce\")\n",
        "    df[\"SE\"]   = pd.to_numeric(df[\"standard_error\"], errors=\"coerce\")\n",
        "    df[\"P\"]    = pd.to_numeric(df[\"p_value\"], errors=\"coerce\")\n",
        "\n",
        "    # --- 5. Sample size (n_samples) ---\n",
        "    df[\"N\"] = pd.to_numeric(df[\"n_samples\"], errors=\"coerce\")\n",
        "\n",
        "    # --- 6. Keep autosomes only (1â€“22) ---\n",
        "    before = df.shape[0]\n",
        "    df = df[df[\"CHR\"].between(1, 22, inclusive=\"both\")]\n",
        "    print(f\"{label}: Dropped {before - df.shape[0]} non-autosomal rows.\")\n",
        "\n",
        "    # --- 7. Drop rows with missing critical fields ---\n",
        "    before = df.shape[0]\n",
        "    df = df.dropna(subset=[\"CHR\", \"BP\", \"SNP\", \"A1\", \"A2\", \"BETA\", \"SE\", \"P\"])\n",
        "    print(f\"{label}: Dropped {before - df.shape[0]} rows with missing fields.\")\n",
        "\n",
        "    # --- 8. Ensure numeric sanity ---\n",
        "    before = df.shape[0]\n",
        "    df = df[\n",
        "        np.isfinite(df[\"BETA\"]) &\n",
        "        np.isfinite(df[\"SE\"]) &\n",
        "        np.isfinite(df[\"P\"]) &\n",
        "        (df[\"SE\"] > 0)\n",
        "    ]\n",
        "    print(f\"{label}: Dropped {before - df.shape[0]} rows with invalid numeric values.\")\n",
        "\n",
        "    # --- 9. Final clean selection ---\n",
        "    clean = df[[\"CHR\", \"BP\", \"SNP\", \"A1\", \"A2\", \"BETA\", \"SE\", \"P\", \"N\"]].copy()\n",
        "    clean = clean.sort_values([\"CHR\", \"BP\"]).reset_index(drop=True)\n",
        "\n",
        "    print(f\"{label}: Final clean shape: {clean.shape}\")\n",
        "    return clean\n",
        "\n",
        "# Clean both GWAS tables\n",
        "eur_clean = clean_gwas(eur_df, \"EUR_ccRCC\")\n",
        "afr_clean = clean_gwas(afr_df, \"AFR_ccRCC\")\n",
        "\n",
        "# Save full clean versions\n",
        "eur_clean_path = \"EUR_ccRCC.clean.autosomes.tsv\"\n",
        "afr_clean_path = \"AFR_ccRCC.clean.autosomes.tsv\"\n",
        "\n",
        "eur_clean.to_csv(eur_clean_path, sep=\"\\t\", index=False)\n",
        "afr_clean.to_csv(afr_clean_path, sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"\\nSaved clean files:\")\n",
        "print(\" \", eur_clean_path)\n",
        "print(\" \", afr_clean_path)\n",
        "\n",
        "# Create minimal clumping input files\n",
        "eur_for_clump = eur_clean[[\"SNP\", \"CHR\", \"BP\", \"P\", \"A1\", \"A2\", \"BETA\"]]\n",
        "afr_for_clump = afr_clean[[\"SNP\", \"CHR\", \"BP\", \"P\", \"A1\", \"A2\", \"BETA\"]]\n",
        "\n",
        "eur_for_clump_path = \"EUR_ccRCC.for_clump.tsv\"\n",
        "afr_for_clump_path = \"AFR_ccRCC.for_clump.tsv\"\n",
        "\n",
        "eur_for_clump.to_csv(eur_for_clump_path, sep=\"\\t\", index=False)\n",
        "afr_for_clump.to_csv(afr_for_clump_path, sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"\\nSaved clump files:\")\n",
        "print(\" \", eur_for_clump_path)\n",
        "print(\" \", afr_for_clump_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiaJRtVH3zr8",
        "outputId": "f058cd69-f6ad-4e8c-d212-37f1eb3bfd03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Cleaning EUR_ccRCC ===\n",
            "Original columns: ['chromosome', 'base_pair_location', 'effect_allele', 'other_allele', 'beta', 'standard_error', 'effect_allele_frequency', 'p_value', 'variant_id', 'rsid', 'het_i2', 'het_p_value', 'n_samples', 'n_cases', 'n_studies', 'hm_coordinate_conversion', 'hm_code']\n",
            "EUR_ccRCC: Dropped 0 rows with missing SNP IDs.\n",
            "EUR_ccRCC: Dropped 445595 non-autosomal rows.\n",
            "EUR_ccRCC: Dropped 0 rows with missing fields.\n",
            "EUR_ccRCC: Dropped 0 rows with invalid numeric values.\n",
            "EUR_ccRCC: Final clean shape: (12819265, 9)\n",
            "\n",
            "=== Cleaning AFR_ccRCC ===\n",
            "Original columns: ['chromosome', 'base_pair_location', 'effect_allele', 'other_allele', 'beta', 'standard_error', 'effect_allele_frequency', 'p_value', 'variant_id', 'rsid', 'het_i2', 'het_p_value', 'n_samples', 'n_cases', 'n_studies', 'hm_coordinate_conversion', 'hm_code']\n",
            "AFR_ccRCC: Dropped 0 rows with missing SNP IDs.\n",
            "AFR_ccRCC: Dropped 698435 non-autosomal rows.\n",
            "AFR_ccRCC: Dropped 0 rows with missing fields.\n",
            "AFR_ccRCC: Dropped 0 rows with invalid numeric values.\n",
            "AFR_ccRCC: Final clean shape: (18379162, 9)\n",
            "\n",
            "Saved clean files:\n",
            "  EUR_ccRCC.clean.autosomes.tsv\n",
            "  AFR_ccRCC.clean.autosomes.tsv\n",
            "\n",
            "Saved clump files:\n",
            "  EUR_ccRCC.for_clump.tsv\n",
            "  AFR_ccRCC.for_clump.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying columns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "eur_clean = pd.read_csv(\"EUR_ccRCC.clean.autosomes.tsv\", sep=\"\\t\")\n",
        "afr_clean = pd.read_csv(\"AFR_ccRCC.clean.autosomes.tsv\", sep=\"\\t\")\n",
        "\n",
        "eur_clump = pd.read_csv(\"EUR_ccRCC.for_clump.tsv\", sep=\"\\t\")\n",
        "afr_clump = pd.read_csv(\"AFR_ccRCC.for_clump.tsv\", sep=\"\\t\")\n",
        "\n",
        "print(\"EUR clean shape:\", eur_clean.shape)\n",
        "print(\"AFR clean shape:\", afr_clean.shape)\n",
        "print(\"EUR clump shape:\", eur_clump.shape)\n",
        "print(\"AFR clump shape:\", afr_clump.shape)\n",
        "\n",
        "print(\"\\nEUR clean columns:\", eur_clean.columns.tolist())\n",
        "print(\"AFR clean columns:\", afr_clean.columns.tolist())\n",
        "print(\"\\nEUR clump columns:\", eur_clump.columns.tolist())\n",
        "print(\"AFR clump columns:\", afr_clump.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PZ5rCQQ6KjI",
        "outputId": "e02b35b7-5faa-4710-e169-5e0ba1e7d22f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUR clean shape: (12819265, 9)\n",
            "AFR clean shape: (18379162, 9)\n",
            "EUR clump shape: (12819265, 7)\n",
            "AFR clump shape: (18379162, 7)\n",
            "\n",
            "EUR clean columns: ['CHR', 'BP', 'SNP', 'A1', 'A2', 'BETA', 'SE', 'P', 'N']\n",
            "AFR clean columns: ['CHR', 'BP', 'SNP', 'A1', 'A2', 'BETA', 'SE', 'P', 'N']\n",
            "\n",
            "EUR clump columns: ['SNP', 'CHR', 'BP', 'P', 'A1', 'A2', 'BETA']\n",
            "AFR clump columns: ['SNP', 'CHR', 'BP', 'P', 'A1', 'A2', 'BETA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking consistency and missingness\n",
        "def quick_qc(df, label):\n",
        "    print(f\"\\n=== {label} ===\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDtypes:\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\\nMissing values per column:\")\n",
        "    print(df.isna().sum())\n",
        "\n",
        "quick_qc(eur_clean, \"EUR_clean\")\n",
        "quick_qc(afr_clean, \"AFR_clean\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGWUUXpw6sZp",
        "outputId": "535a33b3-674a-48fa-cb74-8c2e280bd968"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== EUR_clean ===\n",
            "   CHR     BP           SNP A1 A2      BETA        SE         P       N\n",
            "0    1  13668     rs2691328  A  G -0.482482  0.570721  0.397893  305873\n",
            "1    1  14773   rs878915777  T  C  0.059339  0.329717  0.857176  305873\n",
            "2    1  14860   rs533499096  T  G -0.283933  0.318174  0.372188  305873\n",
            "3    1  17626  rs1230374648  A  G -0.017238  0.402357  0.965828  305873\n",
            "4    1  17765   rs373918278  A  G  0.562539  0.497359  0.258033  305873\n",
            "\n",
            "Dtypes:\n",
            "CHR       int64\n",
            "BP        int64\n",
            "SNP      object\n",
            "A1       object\n",
            "A2       object\n",
            "BETA    float64\n",
            "SE      float64\n",
            "P       float64\n",
            "N         int64\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "CHR     0\n",
            "BP      0\n",
            "SNP     0\n",
            "A1      0\n",
            "A2      0\n",
            "BETA    0\n",
            "SE      0\n",
            "P       0\n",
            "N       0\n",
            "dtype: int64\n",
            "\n",
            "=== AFR_clean ===\n",
            "   CHR      BP          SNP A1 A2      BETA        SE         P     N\n",
            "0    1  709040  rs144745434  C  T -0.156402  0.340545  0.646041  3526\n",
            "1    1  722777  rs879352363  A  G -0.630476  0.479140  0.188225  3024\n",
            "2    1  722858  rs879883701  T  C  0.019092  0.214600  0.929109  3526\n",
            "3    1  727242   rs61769339  A  G -0.153505  0.114701  0.180794  3526\n",
            "4    1  727717   rs61769340  C  G  0.143847  0.105927  0.174473  3526\n",
            "\n",
            "Dtypes:\n",
            "CHR       int64\n",
            "BP        int64\n",
            "SNP      object\n",
            "A1       object\n",
            "A2       object\n",
            "BETA    float64\n",
            "SE      float64\n",
            "P       float64\n",
            "N         int64\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "CHR     0\n",
            "BP      0\n",
            "SNP     0\n",
            "A1      0\n",
            "A2      0\n",
            "BETA    0\n",
            "SE      0\n",
            "P       0\n",
            "N       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EUR variants:\", eur_clean.shape[0])\n",
        "print(\"AFR variants:\", afr_clean.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyoI-BVWPBm8",
        "outputId": "d58c4292-e368-4863-9409-d084e48860d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUR variants: 12819265\n",
            "AFR variants: 18379162\n"
          ]
        }
      ]
    }
  ]
}